---
layout: post
title:  "Intership Application Essay"
date:   2020-01-09 0:0:00 +0800
categories: update
---
> Work in progress. Subject to change.

# Please describe one project or research that you focused on. Must include role you played, difficulties, learnings and reflection. (About 800 words)
The project that I am most proud of was a 10-month long research about the semantic segmentation of structural objects. Guided by two Facebook Research Scientists Dr. Saikat Basu and Dr. Guan Pang, we concentrated on improving the connectivity for linear structures by designing loss functions. We evaluated the effectiveness of the proposed loss function by employing alternative metrics, and I solved engineering challenges posed by the significant number of experiment configurations and large amount of data.
Since my second year of study as a Computer Science undergraduate student, I have been working closely with Prof. Yin Wang in the Tongji Deep Learning Lab as a Research Assistant. At the CVPR 2018 DeepGlobe Workshop, with our carefully designed network architecture and post-processing methods, we delightfully ranked 7th out of 85 competitors and won the Finalist, followed by a publication of a workshop paper titled Stacked U-Nets with Multi-Output for Road Extraction. This achievement further encouraged me to investigate more general delinearation problems. In January 2019, I was honored to see that my research was selected as the topic for a funded academic collaboration between Tongji University and Facebook. Knowing that entering the field of fundamental research in Machine Learning requires a deep understanding of principles in statistical learning theories, I targeted this at a publication at a top conference in Computer Vision.
The research began after the DeepGlobe workshop. I noticed that the road segmentation result suffers a lot from poor connectivity, and this problem also happens in many other scenarios, such as cell boundary, road segmentation in Autonomous Driving, and blood vessels. Making things worse, connectivity is important for linear structures, since even a single small gap may cause a significant change to the whole topology. We suppose this defect is mainly caused by the widely used pixel-wise loss functions, such as cross-entropy. While this is correct for empirical risk minimization, the pixel-level losses cannot emphasize the penalization of small prediction gaps for structural segmentation. Thus, to enhance connectivity, I proposed a novel loss function term that is designed to regulate the total variance around the gaps and fragments. I devised two mathematical forms and three spatial forms of the regulation to adapt to regions of different dimensions: 1D polylines for curvilinear objects, 2D squares for polygonal objects, and 3D cubes for polyhedral objects. The computation of the loss function term is differentiable, meaning that the loss function term can be applied to train any deep neural networks and does not add overhead at inference time. 
We need to evaluate the effectiveness of the proposed loss functions. I conducted experiments on four delinearation datasets including road datasets, a cell membranes dataset, and a 3D hepatic Vessel dataset. Models of a number of architectures have been tested: U-Net, D-Linknet, and V-Net. The performance was compared using a range of metrics. We got inspiration from the SpaceNet competition where we used Average Path Length Similarity (APLS) as connectivity metrics for curvilinear structures. We introduced the IoU measurement for polygonal objects. In addition, we calculated the Hausdorff distance and counted the predicted polygons to measure the fragmentation problem. 
The experiments posed significant engineering challenges. To handle the experiments of over 300 configurations and the long-stretched hyper-parameter tuning process, I needed to write code that is highly reusable, parameterized, parallelized, and performant. The code is built on a flexible deep learning framework Fastai v1, whose development I followed closely. I repeatedly refactored the data loader, model and loss function loader, and training loop codes, and parameterized experiments using a script interface. It turns out that my previous knowledge of Linux and skills in software engineering proved to be tremendously beneficial in the sense that without the time spent on refactoring, collaboration and fast experiments without modifying the code would not have been possible. 
The polygon metrics show 2.5–4.3% connectivity improvements and 7.0-14.6% fragment reduction, while maintaining pixel-level metrics. Visual examination of the results shows that improvements mainly come from fewer gaps and fragments as expected. In contrast, existing methods such as CRF as a post-processing step, CRF integrated into the model/loss function, and GAN methods, all of which I have implemented for comparison, usually perform worse than baseline because they rely too much on shallow appearance features. I have fused these ideas into another paper, titled Whole-Object Segmentation Using Regional Variance Losses, and submitted to CVPR 2020 as a co-author.
My research experience in the field of remote sensing in computer vision has given me a deeper understanding of computer vision and equipped me with essential research methodologies. What fascinated me during the design of  the various forms of loss functions was the importance of using notation as a tool of thought and communication. Additionally, I gained the experience of doing research in collaboration with other people. I have learned how to cooperate effectively with my co-author who provided valuable inspiration on how to quantify topological correctness and performed theoretical analysis of synthetic data. I greatly appreciated the helpful guidance in direction and on how to write a paper from my professor and the Facebook research scientists. This experience has honed my essential skills that I will help me to contribute to Sony as a Machine Learning practitioner.

# 2. Please describe what you would like to contribute through the position you are applying in Sony, from the aspect of knowledge/skills or experience. (About 500 words)
Sony is internationally known for its emotion-provoking products that are full of creativity and technology. The PlayStation series has filled my and my brother’s childhood with joy and strengthened friendships in lives. My research experience described in the previous essay has given me a deep understanding of Computer Vision and trained me with essential research methodologies. Also, working as a Machine Learning Engineer has prepared me with useful software engineering skills and communication abilities. I seek to apply my learning by contributing to Sony. I aspire to stay with Sony in the long-term.
Among the three positions I applied for, the one that I’m most interested in is the fascinating “Cooking with AI and Robotics,” particularly Internship 2 that focuses on data science. From August 2019 to January 2020, I was a Machine Learning Engineer and a core member of a startup (Alfasommet). This work experience has not only consolidated my statistical knowledge and software engineering skills but also helped me improve data visualization and communication skills that are vital for a data scientist. In the first month, I worked closely with the CEO to analyze business objectives and optimization targets. During the data exploration stage, I used jupyter notebook to create visualization reports, which gave us a lot of insights into user behaviors and communicated business benefits. Then I designed and built a recommendation system to match users based on tags from data collection, model selection, and feature engineering to real-time inferencing, which improved recall to 60% compared to the 30% of content-based approaches. As the customer base grew steadily, I expanded the feature set to use word embedding to recommend tags proactively to optimize the user experience. I’m delighted that this data product has helped us raise 5 million Chinese Yuan in the angel round and a following 12 million in the pre-A round, and I was certified as an AWS solution architect. I look forward to solving challenging problems at Sony. Because although the technical challenge of building a data product from scratch is significant, doing data science in a startup doesn’t provide the research opportunities that can exercise my advanced statistical skills and satisfy my curiosity. 
I’m also interested in priority 2 because it fascinates me that I can apply my Machine Learning knowledge to an interdisciplinary area. In May 2019, I participated in a competition organized by the National Basic Research Program of China (973 Program) with the well-known civil engineering department of Tongji University. I got inspired by the AWD-LSTM language models to reformulate the time series regression problem as a language model problem so that I can leverage my knowledge of NLP and training tricks. The introduction of the AWD-LSTM model outperformed the traditional random forest model by a large margin of 13%. We have fused the idea into a paper titled Tunnel Boring Machine (TBM) parameter and rock mass prediction using multi- input and output AWD-LSTM, and submitted to Chinese Journal of Rock Mechanics and Engineering.
I also would like to contribute with my C++ skills for priority 3. C++ is my second proficient language, following Python. An example of projects I worked on is a Chess AI for a class project of the Artificial Intelligence class. I implemented Monte Carlo tree search algorithm and the bitboard trick in C++. I led the team to win the first place in the class contest.
